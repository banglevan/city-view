# City View - YOLO & T2I Crowd Detection System

A comprehensive crowd detection and counting system using both YOLO (You Only Look Once) object detection and T2I (Text-to-Image) zero-shot counting models, specifically designed for monitoring urban areas and public spaces.

## ğŸš€ Features

### YOLO Crowd Detection
- **Real-time Detection**: Detect and count people in images and videos
- **High Accuracy**: Uses YOLO-Crowd model optimized for crowd detection
- **Multiple Input Sources**: Support for images, videos, webcam, and RTSP streams
- **Configurable Parameters**: Easy configuration through YAML files
- **Cross-platform**: Works on Windows, Linux, and macOS
- **GPU Acceleration**: CUDA support for faster inference

### T2I Zero-Shot Counting
- **Zero-Shot Learning**: Count objects without training on specific classes
- **Text-Guided Counting**: Use natural language prompts to count objects
- **High Resolution Support**: Handles images with height of 384px while maintaining aspect ratio
- **Attention-Based**: Uses CLIP tokenizer for cross-modal attention
- **Density Map Generation**: Produces density maps for precise counting
- **Flexible Object Classes**: Count any object type through text prompts

## ğŸ§® MPCount (Patch-based Crowd Counting)

MPCount lÃ  module Ä‘áº¿m Ä‘Ã¡m Ä‘Ã´ng dá»±a trÃªn chia áº£nh thÃ nh cÃ¡c patch lá»›n, phÃ¹ há»£p cho áº£nh Ä‘á»™ phÃ¢n giáº£i cao hoáº·c Ä‘Ã¡m Ä‘Ã´ng dÃ y Ä‘áº·c.

### CÃ¡ch sá»­ dá»¥ng

#### 1. Cháº¡y báº±ng dÃ²ng lá»‡nh

```bash
python mp_count/inference.py --img_path "path/to/image.jpg" --model_path "weights/sta.pth" --save_path "results.txt" --vis_dir "visualize" --unit_size 16 --patch_size 3584 --log_para 1000 --device "cuda"
```

#### 2. Sá»­ dá»¥ng file cáº¥u hÃ¬nh YAML

Táº¡o file `mp_count/configs/config.yaml` vá»›i ná»™i dung:

```yaml
img_path: "D:\\city-view\\yolo_crowd\\data\\Crowd_in_street.jpg"  # ÄÆ°á»ng dáº«n áº£nh hoáº·c thÆ° má»¥c áº£nh
model_path: "weights/sta.pth"  # ÄÆ°á»ng dáº«n file trá»ng sá»‘ model
save_path: null                # File lÆ°u káº¿t quáº£ dá»± Ä‘oÃ¡n (máº·c Ä‘á»‹nh: khÃ´ng lÆ°u)
vis_dir: "visualize"           # ThÆ° má»¥c lÆ°u áº£nh trá»±c quan hÃ³a káº¿t quáº£
unit_size: 16                  # KÃ­ch thÆ°á»›c Ä‘Æ¡n vá»‹ resize (thÆ°á»ng Ä‘á»ƒ 16)
patch_size: 3584               # KÃ­ch thÆ°á»›c patch (giáº£m náº¿u bá»‹ OOM)
log_para: 1000                 # Tham sá»‘ log transform (thÆ°á»ng Ä‘á»ƒ 1000)
device: "cuda"                 # Thiáº¿t bá»‹ cháº¡y model ("cuda" hoáº·c "cpu")
```

Sau Ä‘Ã³ cháº¡y:
```bash
python mp_count/inference.py --config mp_count/configs/config.yaml
```

## ğŸ“‹ Requirements

- Python 3.8+
- PyTorch 1.7+
- OpenCV 4.5+
- Transformers 4.0+
- PIL (Pillow)
- CUDA (optional, for GPU acceleration)

## ğŸ› ï¸ Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd city-view
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   # On Windows
   venv\Scripts\activate
   # On Linux/Mac
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Download model weights**
   ```bash
   # YOLO model weights should be placed in the yolo_crowd/weights/ directory
   # yolo-crowd.pt - Main crowd detection model
   
   # T2I model weights should be placed in the t2i_vlm_crowd/weights/ directory
   # best_model_paper.pth - T2I counting model
   ```

## ğŸ¯ Quick Start

### YOLO Crowd Detection

1. **Detect people in an image**
   ```bash
   python yolo_crowd/inference_crowd.py
   ```

2. **Using the CrowdInference class**
   ```python
   from yolo_crowd.inference_crowd import CrowdInference
   
   # Initialize with default config
   crowd_inference = CrowdInference()
   crowd_inference.load_model()
   
   # Run inference on image
   result = crowd_inference.inference('path/to/image.jpg')
   cv2.imshow('Result', result)
   cv2.waitKey(0)
   ```

### T2I Zero-Shot Counting

1. **Count objects using text prompts**
   ```python
   from t2i_vlm_crowd.inference_t2i import T2ICountInference
   
   # Initialize T2I model
   t2i_inference = T2ICountInference()
   
   # Count people in an image
   t2i_inference.inference("path/to/image.jpg", "person")
   
   # Count cars in an image
   t2i_inference.inference("path/to/image.jpg", "car")
   
   # Count any object
   t2i_inference.inference("path/to/image.jpg", "strawberries")
   ```

2. **Using the T2ICountInference class**
   ```python
   from t2i_vlm_crowd.inference_t2i import T2ICountInference
   
   # Initialize with custom model path
   t2i_inference = T2ICountInference(model_path='path/to/model.pth')
   
   # The model automatically:
   # - Resizes images to height=384px while maintaining aspect ratio
   # - Processes text prompts using CLIP tokenizer
   # - Generates attention masks for cross-modal attention
   # - Returns density maps and count predictions
   ```

### Using Configuration

The system supports configuration through YAML files:

```python
from yolo_crowd.config.get_config import get_inference_config

# Load configuration
config = get_inference_config()
print(f"Image size: {config['imgsz']}")
print(f"Confidence threshold: {config['conf_thres']}")
```

## âš™ï¸ Configuration

### YOLO Configuration

Edit `yolo_crowd/config/config.yaml` to customize detection parameters:

```yaml
inference:
  imgsz: 640          # Input image size
  conf_thres: 0.35    # Confidence threshold
  iou_thres: 0.45     # IoU threshold for NMS
  classes: 0          # Filter by class (0 = person)
  agnostic_nms: True  # Class-agnostic NMS
  device: '0'         # CUDA device (use 'cpu' for CPU)
```

### T2I Configuration

T2I model parameters can be adjusted in the `T2ICountInference` class:

```python
# Key parameters:
crop_size = 384       # Patch size for processing large images
batch_size = 16       # Batch size for inference
target_height = 384   # Target image height (maintains aspect ratio)
```

## ğŸ“ Project Structure

```
city-view/
â”œâ”€â”€ yolo_crowd/              # YOLO crowd detection package
â”‚   â”œâ”€â”€ inference_crowd.py   # Main inference script and CrowdInference class
â”‚   â”œâ”€â”€ models/              # Model definitions
â”‚   â”‚   â”œâ”€â”€ yolo.py          # YOLO model implementation
â”‚   â”‚   â”œâ”€â”€ common.py        # Common model components
â”‚   â”‚   â”œâ”€â”€ experimental.py  # Experimental models
â”‚   â”‚   â”œâ”€â”€ yolo_crowd.yaml  # YOLO-Crowd model config
â”‚   â”‚   â””â”€â”€ hub/             # Model hub configurations
â”‚   â”œâ”€â”€ utils/               # Utility functions
â”‚   â”‚   â”œâ”€â”€ datasets.py      # Dataset loading utilities
â”‚   â”‚   â”œâ”€â”€ general.py       # General utilities
â”‚   â”‚   â”œâ”€â”€ plots.py         # Plotting utilities
â”‚   â”‚   â”œâ”€â”€ torch_utils.py   # PyTorch utilities
â”‚   â”‚   â””â”€â”€ ...              # Other utility modules
â”‚   â”œâ”€â”€ config/              # Configuration files
â”‚   â”‚   â”œâ”€â”€ config.yaml      # Main configuration
â”‚   â”‚   â””â”€â”€ get_config.py    # Config loader
â”‚   â”œâ”€â”€ weights/             # Model weights
â”‚   â”‚   â””â”€â”€ yolo-crowd.pt    # Pre-trained crowd detection model
â”‚   â””â”€â”€ data/                # Data and sample images
â”œâ”€â”€ t2i_vlm_crowd/           # T2I zero-shot counting package
â”‚   â”œâ”€â”€ inference_t2i.py     # Main T2I inference script
â”‚   â”œâ”€â”€ models/              # T2I model components
â”‚   â”‚   â”œâ”€â”€ reg_model.py     # Regression model for counting
â”‚   â”‚   â”œâ”€â”€ decoder.py       # Decoder components
â”‚   â”‚   â””â”€â”€ diff_unet.py     # Diffusion UNet
â”‚   â”œâ”€â”€ utils/               # T2I utilities
â”‚   â”‚   â”œâ”€â”€ tools.py         # Patch extraction and reassembly
â”‚   â”‚   â”œâ”€â”€ helper.py        # Helper functions
â”‚   â”‚   â””â”€â”€ trainer.py       # Training utilities
â”‚   â”œâ”€â”€ configs/             # T2I model configurations
â”‚   â”‚   â”œâ”€â”€ v1-inference.yaml # Inference configuration
â”‚   â”‚   â””â”€â”€ v1-5-pruned-emaonly.ckpt # Model checkpoint
â”‚   â”œâ”€â”€ ldm/                 # Latent Diffusion Model components
â”‚   â”‚   â”œâ”€â”€ models/          # LDM model definitions
â”‚   â”‚   â””â”€â”€ modules/         # LDM modules
â”‚   â””â”€â”€ weights/             # T2I model weights
â”‚       â””â”€â”€ best_model_paper.pth # Pre-trained T2I model
â”œâ”€â”€ .gitignore              # Git ignore rules
â”œâ”€â”€ .gitmodules             # Git submodules configuration
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md               # This file
```

## ğŸ”§ Configuration Parameters

### YOLO Inference Settings

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `imgsz` | int | `640` | Input image size (pixels) |
| `conf_thres` | float | `0.35` | Confidence threshold |
| `iou_thres` | float | `0.45` | IoU threshold for NMS |
| `classes` | int | `0` | Filter by class (0 = person) |
| `agnostic_nms` | bool | `True` | Class-agnostic NMS |
| `device` | str | `'0'` | CUDA device (use 'cpu' for CPU) |

### T2I Model Settings

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `crop_size` | int | `384` | Patch size for processing |
| `batch_size` | int | `16` | Batch size for inference |
| `target_height` | int | `384` | Target image height |
| `device` | str | `'cuda'` | Device for inference |

## ğŸ¯ Use Cases

### YOLO Crowd Detection
- **Real-time monitoring**: Live video streams from cameras
- **Event management**: Crowd counting at events and gatherings
- **Safety monitoring**: Occupancy limits and social distancing
- **Traffic analysis**: Pedestrian flow in urban areas

### T2I Zero-Shot Counting
- **Flexible object counting**: Count any object type through text prompts
- **High-precision counting**: Density map-based approach
- **No training required**: Zero-shot learning capabilities
- **Research applications**: Novel object counting scenarios

## ğŸ” Model Comparison

| Feature | YOLO Crowd | T2I Zero-Shot |
|---------|------------|---------------|
| **Speed** | Fast real-time | Moderate |
| **Accuracy** | High for people | High for any object |
| **Training** | Requires training data | Zero-shot |
| **Flexibility** | Fixed to trained classes | Any object via text |
| **Input** | Images/videos | Images + text prompts |
| **Output** | Bounding boxes + counts | Density maps + counts |

## ğŸš€ Advanced Usage

### Combining Both Models

```python
from yolo_crowd.inference_crowd import CrowdInference
from t2i_vlm_crowd.inference_t2i import T2ICountInference

# Initialize both models
yolo_inference = CrowdInference()
t2i_inference = T2ICountInference()

# Use YOLO for real-time people detection
yolo_result = yolo_inference.inference('crowd.jpg')

# Use T2I for specific object counting
t2i_result = t2i_inference.inference('crowd.jpg', 'person')
```

### Custom Text Prompts for T2I

```python
# Count different object types
prompts = [
    "person", "car", "bicycle", "motorcycle",
    "bus", "truck", "traffic light", "fire hydrant",
    "stop sign", "parking meter", "bench", "bird",
    "cat", "dog", "horse", "sheep", "cow",
    "elephant", "bear", "zebra", "giraffe"
]

for prompt in prompts:
    result = t2i_inference.inference('image.jpg', prompt)
    print(f"Count of {prompt}: {result}")
```

## ğŸ“ Notes

- **Image Resizing**: T2I model automatically resizes images to height=384px while maintaining aspect ratio
- **Memory Usage**: T2I model may require more GPU memory due to transformer architecture
- **Batch Processing**: T2I supports batch processing for multiple images
- **Attention Masks**: T2I uses CLIP tokenizer to generate attention masks for text prompts
- **Refactored Structure**: Project has been refactored into separate `yolo_crowd` and `t2i_vlm_crowd` packages for better organization
